{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5414648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a5aa99",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "\n",
    "<img src=\"./resources/gptarch.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990a8ec2",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57a2de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e25e92d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG = {\n",
    "    \"vocab_size\":tokenizer.n_vocab,\n",
    "    \"context_length\":1024,\n",
    "    \"emb_dim\":768,\n",
    "    \"n_heads\":12,\n",
    "    \"n_layers\":12,                  # Number of transformer layers\n",
    "    \"drop_rate\":0.1,\n",
    "    \"qkv_bias\":False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9f38cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'context_length': 1024,\n",
       " 'emb_dim': 768,\n",
       " 'n_heads': 12,\n",
       " 'n_layers': 12,\n",
       " 'drop_rate': 0.1,\n",
       " 'qkv_bias': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e559a357",
   "metadata": {},
   "source": [
    "# Transformer Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b769ab",
   "metadata": {},
   "source": [
    "<img src=\"./resources/gpttf.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0ea58a",
   "metadata": {},
   "source": [
    "## Normalizing Activations with layer normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "997e13ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2961, 0.5166, 0.2517, 0.6886],\n",
       "        [0.0740, 0.8665, 0.1366, 0.1025],\n",
       "        [0.1841, 0.7264, 0.3153, 0.6871],\n",
       "        [0.0756, 0.1966, 0.3164, 0.4017],\n",
       "        [0.1186, 0.8274, 0.3821, 0.6605]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch = torch.rand(5,4)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eec766de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6374, 0.3983, 0.0873, 0.0000, 0.0000, 0.5753, 0.0609, 0.0043],\n",
       "        [0.2929, 0.3200, 0.0000, 0.0000, 0.0000, 0.2298, 0.0381, 0.0000],\n",
       "        [0.6254, 0.4421, 0.0000, 0.0000, 0.0000, 0.5259, 0.0636, 0.0297],\n",
       "        [0.4001, 0.2804, 0.1059, 0.0000, 0.0000, 0.5429, 0.0369, 0.0000],\n",
       "        [0.6079, 0.4485, 0.0000, 0.0000, 0.0000, 0.4893, 0.0605, 0.0403]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = torch.nn.Sequential(nn.Linear(4,8),nn.ReLU())\n",
    "out = layer(batch)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89698c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2204],\n",
      "        [0.1101],\n",
      "        [0.2108],\n",
      "        [0.1708],\n",
      "        [0.2058]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0741],\n",
      "        [0.0208],\n",
      "        [0.0732],\n",
      "        [0.0447],\n",
      "        [0.0681]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out.mean(dim=-1,keepdim=True))\n",
    "print(out.var(dim=-1,keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58a2d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,emb_dim,unbias=False):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "        self.unbiased = unbias\n",
    "        \n",
    "    def forward(self,x):\n",
    "        mean = x.mean(dim=-1,keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=self.unbiased)\n",
    "        norm_x = (x-mean)/torch.sqrt(var+self.eps)\n",
    "        return self.scale*norm_x+self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6ab8158",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_layer = LayerNorm(out.shape[-1])\n",
    "logit = norm_layer(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51d522a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6378,  0.6984, -0.5228, -0.8658, -0.8658,  1.3939, -0.6266, -0.8489],\n",
       "        [ 1.3553,  1.5559, -0.8163, -0.8163, -0.8163,  0.8877, -0.5336, -0.8163],\n",
       "        [ 1.6377,  0.9137, -0.8330, -0.8330, -0.8330,  1.2449, -0.5817, -0.7157],\n",
       "        [ 1.1597,  0.5544, -0.3281, -0.8637, -0.8637,  1.8819, -0.6769, -0.8637],\n",
       "        [ 1.6474,  0.9942, -0.8432, -0.8432, -0.8432,  1.1615, -0.5955, -0.6780]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85d3cfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.2352e-08],\n",
      "        [ 3.7253e-08],\n",
      "        [ 1.4901e-08],\n",
      "        [ 8.1956e-08],\n",
      "        [-2.9802e-08]], grad_fn=<MeanBackward1>)\n",
      "tensor([[1.1427],\n",
      "        [1.1422],\n",
      "        [1.1427],\n",
      "        [1.1426],\n",
      "        [1.1427]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(logit.mean(dim=-1,keepdim=True))\n",
    "print(logit.var(dim=-1,keepdim=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f26e208",
   "metadata": {},
   "source": [
    "## Feed Forward network and GeLU activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e729da37",
   "metadata": {},
   "source": [
    "#### GELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b06e25a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return 0.5*x*(1+torch.tanh(torch.sqrt(torch.tensor(2.0/torch.pi))*(x+0.044715*torch.pow(x,3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afc042c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5789, 0.9131, 0.0275, 0.1634]],\n",
       "\n",
       "        [[0.3009, 0.5201, 0.3834, 0.4451]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.rand(2,1,4)\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c77e614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4160, 0.7481, 0.0141, 0.0923]],\n",
       "\n",
       "        [[0.1860, 0.3632, 0.2489, 0.2990]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gelu = GeLU()\n",
    "gelu(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a0c0f7",
   "metadata": {},
   "source": [
    "#### Feed Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a34706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"],4*cfg[\"emb_dim\"]),\n",
    "            GeLU(),\n",
    "            nn.Linear(4*cfg[\"emb_dim\"],cfg[\"emb_dim\"])\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fa4e8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6, 768])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.rand(5,6,768)\n",
    "\n",
    "ffn = FeedForward(GPT_CONFIG)\n",
    "\n",
    "out = ffn(inputs)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb432521",
   "metadata": {},
   "source": [
    "### Transformer Block "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c72df8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MultiHeadAttention import MultiHeadAttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66d6fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttentionLayer(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ffn = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.dropout = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.attention(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + shortcut\n",
    "        \n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + shortcut\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "612e4464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "x = torch.rand(2, 4, 768)  # Shape: [batch_size, num_tokens, emb_dim]\n",
    "block = TransformerBlock(GPT_CONFIG)\n",
    "output = block(x)\n",
    "\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a164720",
   "metadata": {},
   "source": [
    "# GPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bff95de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93469684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[15496,    11,   314,   716],\n",
      "        [ 7454,   345,  3151,   534]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "batch = []\n",
    "\n",
    "txt1 = \"Hello, I am\"\n",
    "txt2 = \"Once you reach your\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)).to(dtype=torch.int))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)).to(dtype=torch.int))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f5ccf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[15496,    11,   314,   716],\n",
      "        [ 7454,   345,  3151,   534]], dtype=torch.int32)\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.1654, -0.5162, -0.3986,  ..., -0.2268,  0.3410, -0.4689],\n",
      "         [ 0.9846, -0.8799, -0.6668,  ..., -0.4058,  0.2684, -0.2774],\n",
      "         [ 0.9290, -0.1931,  0.1867,  ...,  0.0074,  0.7953,  0.1561],\n",
      "         [-0.3444,  0.0945, -0.2120,  ...,  1.4769, -0.7510, -0.9095]],\n",
      "\n",
      "        [[-0.7491, -0.5921, -0.3185,  ..., -0.7649, -0.0388, -0.6094],\n",
      "         [ 0.4283, -0.2397, -1.0481,  ...,  0.2326,  0.6545, -0.5148],\n",
      "         [ 0.9426,  0.0823, -0.5413,  ..., -0.1721, -1.1168, -0.4192],\n",
      "         [-0.2581,  0.2348,  0.1501,  ...,  0.7086, -0.0064, -1.1429]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG)\n",
    "\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0cff1f",
   "metadata": {},
   "source": [
    "## Sample Text Generation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46443de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        logits = logits[:, -1, :]  \n",
    "\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce161437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [7454, 345, 3151, 534]\n",
      "tensor([[7454,  345, 3151,  534]])\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Once you reach your\"\n",
    "\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(encoded_tensor)\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ebe2d035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[ 7454,   345,  3151,   534, 20860, 49329, 41977,  5729, 47875,  1508]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval() # disable dropout\n",
    "\n",
    "out = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=encoded_tensor, \n",
    "    max_new_tokens=6, \n",
    "    context_size=GPT_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f02ff9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once you reach yourcommunications Bagg66666666 apparentlyigroupailable\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429605e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
