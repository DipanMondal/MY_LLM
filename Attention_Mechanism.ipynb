{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "658f1c23",
   "metadata": {},
   "source": [
    "# Sample Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "905e3d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken \n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1da90c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7621, 0.9305, 0.4437],\n",
      "        [0.9226, 0.6790, 0.3216],\n",
      "        [0.8928, 0.1642, 0.7812],\n",
      "        [0.1020, 0.6221, 0.3596],\n",
      "        [0.7363, 0.5734, 0.9516]])\n"
     ]
    }
   ],
   "source": [
    "# This is a embedding of a single sentence\n",
    "inputs = torch.rand(5,3)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e64aea2",
   "metadata": {},
   "source": [
    "## Simple Self-Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3060618",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_score = inputs @ inputs.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "859488b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n",
      "tensor([[1.6435, 1.4776, 1.1798, 0.8162, 1.5169],\n",
      "        [1.4776, 1.4156, 1.1864, 0.6322, 1.3747],\n",
      "        [1.1798, 1.1864, 1.4343, 0.4741, 1.4949],\n",
      "        [0.8162, 0.6322, 0.4741, 0.5267, 0.7740],\n",
      "        [1.5169, 1.3747, 1.4949, 0.7740, 1.7765]])\n"
     ]
    }
   ],
   "source": [
    "print(attention_score.shape)\n",
    "print(attention_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8180e8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights = torch.softmax(attention_score,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dd989fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2636, 0.2233, 0.1658, 0.1152, 0.2322],\n",
       "        [0.2488, 0.2339, 0.1860, 0.1068, 0.2245],\n",
       "        [0.1938, 0.1951, 0.2499, 0.0957, 0.2656],\n",
       "        [0.2353, 0.1958, 0.1671, 0.1762, 0.2256],\n",
       "        [0.2166, 0.1878, 0.2118, 0.1030, 0.2807]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af6ca2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(attention_weights,dim=1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31d1351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vector = attention_weights @ inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04dd5104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7375, 0.6289, 0.5806],\n",
       "        [0.7476, 0.6161, 0.5829],\n",
       "        [0.7561, 0.5656, 0.6311],\n",
       "        [0.6932, 0.6183, 0.5760],\n",
       "        [0.7447, 0.5889, 0.6262]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdea9ac",
   "metadata": {},
   "source": [
    "## Simple Self-Attention with Trainable Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90af45ff",
   "metadata": {},
   "source": [
    "We use three matrixes Query, Keys and Values. \n",
    "\n",
    "We can change the input shape. \n",
    "\n",
    "    d_in = inputs.shape[-1] & d_out = 128 (desired value)\n",
    "    \n",
    "Q.shape = (d_in x d_out)\n",
    "\n",
    "K.shape = (d_in x d_out)\n",
    "\n",
    "V.shape = (d_in x d_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f165863",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in = inputs.shape[-1]\n",
    "d_out = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e3e4f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in,d_out))\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in,d_out))\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in,d_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38eac71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf557ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4495, 1.4367, 0.6547, 1.4572, 0.5055, 1.1065, 0.6810, 0.8879],\n",
       "        [0.4363, 1.2359, 0.5691, 1.3142, 0.3941, 1.1237, 0.5456, 0.6834],\n",
       "        [0.3872, 1.2268, 0.5749, 1.2435, 0.7453, 1.2693, 0.6713, 0.9251],\n",
       "        [0.1873, 0.8021, 0.3592, 0.7352, 0.3615, 0.4240, 0.4397, 0.6137],\n",
       "        [0.4364, 1.5842, 0.7297, 1.5295, 0.9101, 1.3152, 0.8879, 1.2409]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = inputs @ W_query\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8d154b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0576, 1.2614, 1.2652, 1.4892, 0.9615, 0.5904, 1.0312, 1.3157],\n",
       "        [0.8715, 1.1612, 1.0240, 1.3988, 1.0302, 0.4440, 1.0912, 1.2296],\n",
       "        [0.6806, 0.8848, 0.7532, 1.5973, 1.1754, 0.4964, 1.1814, 1.1991],\n",
       "        [0.6208, 0.5896, 0.7614, 0.7075, 0.3053, 0.4113, 0.3383, 0.6150],\n",
       "        [1.0007, 1.1101, 1.1619, 1.8067, 1.1447, 0.7241, 1.1688, 1.4002]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = inputs @ W_key\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d44897f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0316, 1.7072, 1.1795, 0.7497, 1.0151, 1.7037, 0.7740, 0.5364],\n",
       "        [1.0986, 1.5399, 1.1081, 0.7692, 0.9671, 1.4956, 0.7223, 0.4026],\n",
       "        [1.1105, 1.2778, 0.9913, 0.9067, 0.6565, 1.3423, 1.1267, 0.6877],\n",
       "        [0.3233, 0.8458, 0.5366, 0.2812, 0.4277, 0.9028, 0.3991, 0.3949],\n",
       "        [1.0919, 1.6196, 1.1675, 0.9261, 0.7988, 1.7326, 1.2298, 0.8863]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = inputs @ W_value\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c4183f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.2958,  7.6157,  7.4103,  4.0416,  8.8571],\n",
       "        [ 7.2019,  6.5772,  6.4034,  3.5502,  7.7037],\n",
       "        [ 7.9116,  7.2915,  7.1765,  3.8269,  8.5160],\n",
       "        [ 4.6181,  4.2860,  4.1728,  2.1939,  4.9176],\n",
       "        [ 9.8606,  9.1228,  8.9507,  4.7251, 10.5758]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_score = queries @ keys.T\n",
    "attention_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "863d3b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2526, 0.1986, 0.1847, 0.0561, 0.3080],\n",
       "        [0.2484, 0.1992, 0.1873, 0.0683, 0.2967],\n",
       "        [0.2470, 0.1984, 0.1905, 0.0583, 0.3059],\n",
       "        [0.2337, 0.2078, 0.1996, 0.0992, 0.2598],\n",
       "        [0.2534, 0.1952, 0.1837, 0.0412, 0.3263]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = keys.shape[-1]\n",
    "\n",
    "attention_weight = torch.softmax((attention_score/d_k**0.5),dim=1)\n",
    "attention_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a059edfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0383, 1.5193, 1.0908, 0.8106, 0.8398, 1.5596, 0.9482, 0.6376],\n",
       "        [1.0292, 1.5086, 1.0825, 0.8033, 0.8341, 1.5484, 0.9394, 0.6322],\n",
       "        [1.0371, 1.5152, 1.0884, 0.8101, 0.8369, 1.5557, 0.9485, 0.6374],\n",
       "        [1.0067, 1.4785, 1.0602, 0.7844, 0.8191, 1.5164, 0.9149, 0.6157],\n",
       "        [1.0496, 1.5315, 1.1006, 0.8206, 0.8450, 1.5731, 0.9620, 0.6464]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector = attention_weight @ values\n",
    "context_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dae0358",
   "metadata": {},
   "source": [
    "## Self-Attention class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03fdd6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_k, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = torch.nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_key = torch.nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_value = torch.nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        queries = self.W_query(x)\n",
    "        keys = self.W_key(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        attention_score = queries @ keys.T\n",
    "        attention_weight = torch.softmax((attention_score/keys.shape[-1]**0.5),dim=-1)\n",
    "        context_vec = attention_weight @ values\n",
    "        return context_vec;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce69344a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7621, 0.9305, 0.4437],\n",
       "        [0.9226, 0.6790, 0.3216],\n",
       "        [0.8928, 0.1642, 0.7812],\n",
       "        [0.1020, 0.6221, 0.3596],\n",
       "        [0.7363, 0.5734, 0.9516]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a1f9ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6793,  0.2955, -0.5741,  0.0871,  0.0271, -0.3884, -0.4559,  0.6883],\n",
       "        [ 0.6807,  0.2957, -0.5745,  0.0888,  0.0285, -0.3896, -0.4556,  0.6891],\n",
       "        [ 0.6843,  0.2954, -0.5765,  0.0954,  0.0381, -0.3936, -0.4518,  0.6917],\n",
       "        [ 0.6773,  0.2943, -0.5735,  0.0872,  0.0302, -0.3876, -0.4531,  0.6869],\n",
       "        [ 0.6825,  0.2953, -0.5759,  0.0927,  0.0353, -0.3919, -0.4527,  0.6906]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_in = inputs.shape[-1]\n",
    "d_out = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "ob = SelfAttention(d_in,d_out)\n",
    "ob(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c28a79a",
   "metadata": {},
   "source": [
    "## Casual Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea50d7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1459, 0.0969, 0.7076],\n",
       "         [0.5112, 0.7050, 0.0114],\n",
       "         [0.4702, 0.8526, 0.7320],\n",
       "         [0.5183, 0.5983, 0.4527],\n",
       "         [0.2251, 0.3111, 0.1955]],\n",
       "\n",
       "        [[0.9153, 0.7751, 0.6749],\n",
       "         [0.1166, 0.8858, 0.6568],\n",
       "         [0.8459, 0.3033, 0.6060],\n",
       "         [0.9882, 0.8363, 0.9010],\n",
       "         [0.3950, 0.8809, 0.1084]],\n",
       "\n",
       "        [[0.5432, 0.2185, 0.3834],\n",
       "         [0.3720, 0.5374, 0.9551],\n",
       "         [0.7475, 0.4979, 0.8549],\n",
       "         [0.2438, 0.7577, 0.4536],\n",
       "         [0.4130, 0.5585, 0.1170]],\n",
       "\n",
       "        [[0.5578, 0.6681, 0.9275],\n",
       "         [0.3443, 0.6800, 0.9998],\n",
       "         [0.2855, 0.9753, 0.2518],\n",
       "         [0.7204, 0.6959, 0.6397],\n",
       "         [0.8954, 0.2979, 0.6314]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_input = torch.rand(4,5,3)\n",
    "batch_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de4336e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CasualSelfAttention(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out, dropout, context_length, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = torch.nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_key = torch.nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_value = torch.nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length,context_length),diagonal=1))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        batch_sz ,num_tokens, d_in = x.shape\n",
    "        queries = self.W_query(x)\n",
    "        keys = self.W_key(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        attention_score = queries @ keys.transpose(1,2)\n",
    "        attention_score.masked_fill_(\n",
    "            self.mask.bool()[:num_tokens,:num_tokens],-torch.inf)\n",
    "        \n",
    "        attention_weight = torch.softmax((attention_score/keys.shape[-1]**0.5),dim=-1)\n",
    "        \n",
    "        attention_weight = self.dropout(attention_weight)\n",
    "        context_vec = attention_weight @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e04b76f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = batch_input.shape[1]\n",
    "dropout = 0.0\n",
    "d_in = batch_input.shape[-1]\n",
    "d_out = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "ca = CasualSelfAttention(d_in,d_out,dropout,context_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2121b227",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ca(batch_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8bf4a0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2543,  0.1893, -0.3156, -0.2557, -0.3265, -0.0626, -0.4241,\n",
       "           0.3383],\n",
       "         [ 0.3759,  0.1769, -0.3647, -0.0093,  0.0024, -0.2020, -0.2818,\n",
       "           0.4137],\n",
       "         [ 0.4877,  0.2316, -0.4990, -0.0266,  0.0284, -0.2606, -0.3621,\n",
       "           0.5537],\n",
       "         [ 0.5084,  0.2354, -0.5043, -0.0032,  0.0435, -0.2778, -0.3616,\n",
       "           0.5659],\n",
       "         [ 0.4597,  0.2109, -0.4537,  0.0041,  0.0478, -0.2533, -0.3208,\n",
       "           0.5099]],\n",
       "\n",
       "        [[ 0.8828,  0.3709, -0.7252,  0.1622,  0.0849, -0.5184, -0.5523,\n",
       "           0.8784],\n",
       "         [ 0.6921,  0.3256, -0.7218, -0.0315,  0.0798, -0.3738, -0.4960,\n",
       "           0.7940],\n",
       "         [ 0.6895,  0.3127, -0.6290,  0.0328,  0.0173, -0.3819, -0.4906,\n",
       "           0.7309],\n",
       "         [ 0.7661,  0.3452, -0.6851,  0.0477,  0.0123, -0.4262, -0.5429,\n",
       "           0.8028],\n",
       "         [ 0.7174,  0.3149, -0.6558,  0.0682,  0.0845, -0.4089, -0.4702,\n",
       "           0.7592]],\n",
       "\n",
       "        [[ 0.4352,  0.1834, -0.2946,  0.0959, -0.0555, -0.2525, -0.3028,\n",
       "           0.3929],\n",
       "         [ 0.5066,  0.2588, -0.4774, -0.0759, -0.1439, -0.2492, -0.4636,\n",
       "           0.5527],\n",
       "         [ 0.5847,  0.2907, -0.5289, -0.0550, -0.1498, -0.2956, -0.5148,\n",
       "           0.6222],\n",
       "         [ 0.5597,  0.2770, -0.5438, -0.0593, -0.0798, -0.2857, -0.4712,\n",
       "           0.6193],\n",
       "         [ 0.5356,  0.2534, -0.5106, -0.0153, -0.0185, -0.2859, -0.4109,\n",
       "           0.5840]],\n",
       "\n",
       "        [[ 0.7129,  0.3678, -0.7313, -0.1358, -0.1365, -0.3489, -0.6395,\n",
       "           0.8167],\n",
       "         [ 0.6676,  0.3633, -0.7394, -0.2050, -0.1631, -0.3081, -0.6459,\n",
       "           0.8036],\n",
       "         [ 0.6283,  0.3201, -0.7068, -0.1243, -0.0025, -0.3143, -0.5203,\n",
       "           0.7589],\n",
       "         [ 0.6573,  0.3208, -0.6930, -0.0703,  0.0152, -0.3425, -0.5118,\n",
       "           0.7613],\n",
       "         [ 0.6648,  0.3147, -0.6437, -0.0223, -0.0091, -0.3551, -0.5061,\n",
       "           0.7313]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d70d5a",
   "metadata": {},
   "source": [
    "# Multihead Casual Self Attention "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e0ef2e",
   "metadata": {},
   "source": [
    "### Stacking multiple casual self attention layers paralally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0cd91346",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(torch.nn.Module):\n",
    "    def __init__(self,d_in,d_out,context_length,dropout,qkv_bias=False,num_head=2):\n",
    "        super().__init__()\n",
    "        self.heads = torch.nn.ModuleList([CasualSelfAttention(d_in=d_in,d_out=d_out,context_length=context_length,dropout=dropout,qkv_bias=qkv_bias) for _ in range(num_head)])\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return torch.cat([head(x) for head in self.heads],dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7f132a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = batch_input.shape[1]\n",
    "dropout = 0.0\n",
    "d_in = batch_input.shape[-1]\n",
    "d_out = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "mha = MultiHeadAttentionLayer(d_in=d_in,d_out=d_out,context_length=context_length,dropout=dropout,num_head=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a491d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = mha(batch_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e23a9dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5, 96])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0213c13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2543,  0.1893, -0.3156,  ...,  0.3447,  0.4177,  0.2244],\n",
       "         [ 0.3759,  0.1769, -0.3647,  ...,  0.4790,  0.4910,  0.0391],\n",
       "         [ 0.4877,  0.2316, -0.4990,  ...,  0.6047,  0.6287,  0.0344],\n",
       "         [ 0.5084,  0.2354, -0.5043,  ...,  0.6281,  0.6488,  0.0401],\n",
       "         [ 0.4597,  0.2109, -0.4537,  ...,  0.5671,  0.5853,  0.0342]],\n",
       "\n",
       "        [[ 0.8828,  0.3709, -0.7252,  ...,  1.0484,  1.0458,  0.1661],\n",
       "         [ 0.6921,  0.3256, -0.7218,  ...,  0.8800,  0.9161,  0.0352],\n",
       "         [ 0.6895,  0.3127, -0.6290,  ...,  0.8424,  0.8612,  0.1372],\n",
       "         [ 0.7661,  0.3452, -0.6851,  ...,  0.9309,  0.9485,  0.1665],\n",
       "         [ 0.7174,  0.3149, -0.6558,  ...,  0.8694,  0.8813,  0.0835]],\n",
       "\n",
       "        [[ 0.4352,  0.1834, -0.2946,  ...,  0.5007,  0.4941,  0.1883],\n",
       "         [ 0.5066,  0.2588, -0.4774,  ...,  0.6167,  0.6530,  0.1904],\n",
       "         [ 0.5847,  0.2907, -0.5289,  ...,  0.7078,  0.7429,  0.2220],\n",
       "         [ 0.5597,  0.2770, -0.5438,  ...,  0.6882,  0.7246,  0.1459],\n",
       "         [ 0.5356,  0.2534, -0.5106,  ...,  0.6527,  0.6773,  0.1017]],\n",
       "\n",
       "        [[ 0.7129,  0.3678, -0.7313,  ...,  0.8968,  0.9609,  0.1854],\n",
       "         [ 0.6676,  0.3633, -0.7394,  ...,  0.8582,  0.9375,  0.1646],\n",
       "         [ 0.6283,  0.3201, -0.7068,  ...,  0.8000,  0.8561,  0.0281],\n",
       "         [ 0.6573,  0.3208, -0.6930,  ...,  0.8281,  0.8728,  0.0579],\n",
       "         [ 0.6648,  0.3147, -0.6437,  ...,  0.8214,  0.8539,  0.1214]]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1150430",
   "metadata": {},
   "source": [
    "### Multi head attention with combined matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cbe36e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class MultiHeadAttentionLayer(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads \n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  \n",
    "\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        \n",
    "        return context_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1212075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = batch_input.shape[1]\n",
    "dropout = 0.0\n",
    "d_in = batch_input.shape[-1]\n",
    "num_heads = 12\n",
    "d_out = 8*num_heads\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "mha = MultiHeadAttentionLayer(d_in=d_in,d_out=d_out,context_length=context_length,dropout=dropout,num_heads=num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6c2439ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = mha(batch_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "abed7a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5, 96])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "669f81b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1579,  0.2051, -0.2036,  ...,  0.2524,  0.1098,  0.0859],\n",
       "         [ 0.0522,  0.1414, -0.2023,  ...,  0.0997,  0.1077,  0.1170],\n",
       "         [ 0.0709,  0.1912, -0.2327,  ...,  0.1151,  0.1214,  0.1673],\n",
       "         [ 0.0653,  0.2020, -0.2400,  ...,  0.1119,  0.1164,  0.1710],\n",
       "         [ 0.0529,  0.1757, -0.2272,  ...,  0.1049,  0.1070,  0.1511]],\n",
       "\n",
       "        [[ 0.0944,  0.4150, -0.3520,  ...,  0.1285,  0.1355,  0.2875],\n",
       "         [ 0.0947,  0.2966, -0.3042,  ...,  0.1338,  0.1250,  0.2499],\n",
       "         [ 0.1032,  0.3218, -0.3034,  ...,  0.1455,  0.1265,  0.2263],\n",
       "         [ 0.1185,  0.3665, -0.3292,  ...,  0.1536,  0.1321,  0.2522],\n",
       "         [ 0.0855,  0.3096, -0.3079,  ...,  0.1134,  0.1246,  0.2384]],\n",
       "\n",
       "        [[ 0.0641,  0.2157, -0.2313,  ...,  0.1242,  0.0978,  0.1131],\n",
       "         [ 0.1239,  0.2810, -0.2597,  ...,  0.1950,  0.1219,  0.1643],\n",
       "         [ 0.1373,  0.3280, -0.2832,  ...,  0.2037,  0.1272,  0.1897],\n",
       "         [ 0.1173,  0.2820, -0.2719,  ...,  0.1741,  0.1247,  0.1872],\n",
       "         [ 0.0880,  0.2434, -0.2565,  ...,  0.1400,  0.1181,  0.1747]],\n",
       "\n",
       "        [[ 0.1686,  0.3929, -0.3227,  ...,  0.2319,  0.1438,  0.2588],\n",
       "         [ 0.1778,  0.3737, -0.3121,  ...,  0.2464,  0.1445,  0.2520],\n",
       "         [ 0.1166,  0.2771, -0.2824,  ...,  0.1611,  0.1381,  0.2314],\n",
       "         [ 0.1112,  0.2922, -0.2895,  ...,  0.1530,  0.1366,  0.2341],\n",
       "         [ 0.1141,  0.3126, -0.2953,  ...,  0.1576,  0.1325,  0.2259]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f2c6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
